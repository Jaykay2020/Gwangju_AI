{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1stweek.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOrL7Of+GnA2AiFZk5DlSbg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jaykay2020/Gwangju_AI/blob/master/1stweek.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c0Onl1gJbXfr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aUwJOzxrb-Tq",
        "colab_type": "text"
      },
      "source": [
        "#1주차 과제\n",
        "##**언어, 음성, 이미지, 자율주행**의 각 분야에서 인공지능이 적용된 사례\n",
        "    \n",
        "1. 언어 - 기계 번역   \n",
        "![Google translate](https://user-images.githubusercontent.com/63007709/82991344-7cc32d00-a038-11ea-8861-8ca904ddf57c.png)\n",
        "\n",
        "  구글 번역 서비스는 가장 대표적인 기계 번역 서비스로서, 기존의 '어구 기반 기계 번역(Phrase Machine Translation)'의 한계를 넘기 위해 '신경망 번역(Neural Machine Translation)'을 도입해서 번역 서비스의 질을 크게 끌어올렸다. 각 모델의 특징은 다음과 같다.\n",
        "\n",
        "* 어구 기반 기계 번역: 단어 또는 어구를 먼저 번역한 후 이를 퍼즐 맞추듯이 조립. \n",
        "* 신경망 번역: 인터넷 상에서 인간이 미리 번역해 놓은 콘텐츠를 웹 크롤링을 활용해 수집하여, 이 데이터에 기반하여 초기 번역 시스템을 구축. 해당 시스템의 감독학습을 끝낸 후, 번역 모델이 스스로 언어 데이터를 수집하고 이를 바탕으로 스스로의 성능을 강화.(비감독학습)   \n",
        "\n",
        "  Link: [ITdongA 기사](https://it.donga.com/25531/)\n",
        "\n",
        "2. 음성 - 인공지능 비서\n",
        "![bixby](https://user-images.githubusercontent.com/63007709/83044689-7efcaa00-a07f-11ea-9268-b5d98fd8aa87.jpg)\n",
        "\n",
        "  빅스비는 2017년 삼성전자에서 개시한 인공지능 비서 서비스이다. 사용자가 음성으로 명령을 내리면 그 내용이 모든 사용자가 공유하는 중앙 서버에 전달되어, 이 중앙 서버에서 명령에 대한 분석이 이루어진 후 빅스비에게 수행 지침을 전달하게 된다. 서버에는 인공지능이 시행착오를 통해 스스로 학습하는 딥러닝 기술이 적용되어 있다. \n",
        "\n",
        "  사용자의 명령어 익식 또한 인공 지능을 통해 구현된다. 연구원이 직접 음성 언어를 입력하여 학습시킨 후, 실제 사용자들이 사용하면서 쌓이는 빅데이터를 기반으로 빅스비가 이해할 수 있는 문장도 늘어나게 된다. 삼성은 이에 더 나아가 사용자의 상태 정보에 기초하여 응답 메세지를 제공하는 방식에 대한 특허를 내며, 빅스비의 인공지능 비서로서의 수행 능력을 업그레이드할 계획이라고 밝혔다.\n",
        "\n",
        "  Link: [ChosunBiz 기사](https://biz.chosun.com/site/data/html_dir/2017/05/07/2017050701576.html)   \n",
        "  Link: [BIZWORLD 기사](http://www.bizwnews.com/news/articleView.html?idxno=13236)\n",
        "\n",
        "\n",
        "3. 이미지 - 인공지능을 이용한 사진 및 비디오 편집\n",
        "\n",
        "* 한국전자통신연구원(ETRI)의 **SC-FEGAN**: 전문 편집 프로그램 없이도 사람의 얼굴 사진을 자연스럽게 편집할 수 있는 기술로, 딥러닝 기법 ‘갠(GAN)’ 기술이 사용되었다. 인공적으로 데이터를 만들고 이를 판별하면서 진짜 같은 가짜 데이터를 만들어내는데 효과적인 기술이다. 기존의 갠 기술에 입력값을 넣어 원하는 결과를 낼 수 있는 알고리즘을 추가함으로써, 사용자가 사진 속에서 자연스럽게 어울리는 이미지를 만들 수 있게 했다.\n",
        "\n",
        "  Link: [GenMedia 기사](http://www.genmedia.co.kr/news/articleView.html?idxno=12829)   \n",
        "\n",
        "* 엔씨소프트의 야구 정보 앱 **PAIGE**: AI 기반의 야구 정보 앱으로, 이미지 인식 기술을 이용하여 생성한 야구 하이라이트 클립을 제공한다. 클립 생성을 위한 문제 접근 방법은 태깅(tagging) 및 검색(retrieval). 이미지 인식 기술을 통해 야구 중계 동영상의 각 시점에 대한 정보를 기록하고, 기록된 정보 하이라이트 검색 키워드를 통해 하이라이트 구간의 시작과 끝 지점을 찾는 방법이다.\n",
        "![baseball image](https://user-images.githubusercontent.com/63007709/83049467-31d00680-a086-11ea-8010-4d42cb5b4892.png)   \n",
        "\n",
        "  이와 같은 기술이 더 잘 구현되기 위해서는 이미지 인식을 넘어서 **video understanding**의 발전이 중요할 것으로 보인다.\n",
        "\n",
        "  Link: [NCSOFT 블로그 칼럼](https://blog.ncsoft.com/%EA%B2%8C%EC%9E%84%EA%B3%BC-ai-10-%EC%9D%B4%EB%AF%B8%EC%A7%80-%EC%9D%B8%EC%8B%9D-%EA%B8%B0%EC%88%A0%EC%9D%84-%EC%9D%B4%EC%9A%A9%ED%95%9C-%EC%95%BC%EA%B5%AC-%ED%95%98%EC%9D%B4%EB%9D%BC%EC%9D%B4/)\n",
        "\n",
        "4. 자율주행 - 자율주행 자동차   \n",
        "  현재 자율주행 관련 기술은 '국제자동차기술자협회(SAE)'가 지난 2016년에 6단계로 분류한 기술을 바탕으로 적용되고 있다. 각 단계가 구현하는 자율주행 수준은 다음과 같다.\n",
        "  \n",
        "* 레벨 0: 무 자율주행. 운전자가 항상 제어할 수 있는 상태\n",
        "* 레벨 1: 운전자 지원. 시스템이 조향 또는 감속, 가속을 수행하는 경우. 예를 들어 차로 유지보조(LFA) 혹은 어댑티브 크루자 컨트롤(ACC)이 포함되는 경우.\n",
        "* 레벨 2: 부분 자율주행. 시스템이 조향과 감속, 가속 모두를 수행하는 경우. LFA와 ACC가 모두 포함된 반자율주행.\n",
        "* 레벨 3: 조건부 지원. 차량이 대부분 스스로 수행하며 센서와 카메라, 라이다 등을 활용해 상황을 파악할 수 있는 상태. 상황에 따라 차량이 운전자에게 운전을 맡길 수 있고, 이 경우 운전자가 즉시 개입.\n",
        "* 레벨 4: 고도 자율주행. 도심이나 고속도로와 같은 곳에서는 차량이 스스로 주행을 하지만, 예상치 못한 지점의 경우 운전자가 개입.\n",
        "* 레벨 5: 완전자율주행. 모든 상황을 차량이 스스로 판단하고 주행에 반영. 운전자의 개입이 없는 수준.\n",
        "\n",
        "  현재 출시되는 차량들은 대부분 레벨 2 수준으로 양산되고 있는데, 예를 들어 자율주행으로 유명한 테슬라의 오토파일럿 기술은 레벨2~3 수준이다. 미국, 독일, 일본 등 자동차 선진국들은 레벨 4 수준의 기술개발을 진행중이며 한국 또한 레벨 4 기술 개발을 위하여 산업부, 과기부 등 4개 부처가 향후 7년간 약 1조원을 투입하기로 결정했다.\n",
        "\n",
        "  Link: [IT dongA 칼럼](https://it.donga.com/30208/)   \n",
        "  Link: [ChosunBiz 기사](https://biz.chosun.com/site/data/html_dir/2020/04/28/2020042801852.html)\n"
      ]
    }
  ]
}